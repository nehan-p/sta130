{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "QZqKEIhFMKVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "9kLOVVZUM8DC",
        "outputId": "a6f2db27-4f24-4923-a1f1-2489c5b6db77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "row_n           0\n",
              "id              1\n",
              "name            0\n",
              "gender          0\n",
              "species         0\n",
              "birthday        0\n",
              "personality     0\n",
              "song           11\n",
              "phrase          0\n",
              "full_id         0\n",
              "url             0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>row_n</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>species</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>birthday</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personality</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>song</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>phrase</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>full_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>url</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "vYyEbF9WQkbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions 2.1"
      ],
      "metadata": {
        "id": "kAh967JHQy0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
        "villagers_df = pd.read_csv(url)\n",
        "\n",
        "# Get the number of rows and columns\n",
        "rows, columns = villagers_df.shape\n",
        "\n",
        "# Output the result\n",
        "print(f\"Number of rows: {rows}\")\n",
        "print(f\"Number of columns: {columns}\")\n",
        "\n",
        "# Optionally, you can also print the column names\n",
        "print(\"\\nColumn names:\")\n",
        "print(villagers_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvGM7gIMQAJ6",
        "outputId": "058ddc3e-f24f-4c12-bafd-19e7941fff09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 391\n",
            "Number of columns: 11\n",
            "\n",
            "Column names:\n",
            "Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
            "       'song', 'phrase', 'full_id', 'url'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2.2"
      ],
      "metadata": {
        "id": "TAVkYQVGQ2cW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The term 'observation' essentially refers to the rows, or the individual, unique data entries from the dataset.  In this case, this refers to the individual characters, which there are 391 of.\n",
        "\n",
        "The term 'variable' is referring to the differentiating factors of all the villagers.  These are the columns in the dataset, referring to things like name, gender, birthday, etc."
      ],
      "metadata": {
        "id": "Da4wCPUnQ4Cs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "bNGUxPOV82w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
        "villagers_df = pd.read_csv(url)\n",
        "\n",
        "# Generate summary statistics for numeric columns\n",
        "summary_statistics = villagers_df.describe()\n",
        "\n",
        "# Get counts for categorical columns\n",
        "species_counts = villagers_df['species'].value_counts()\n",
        "personality_counts = villagers_df['personality'].value_counts()\n",
        "gender_counts = villagers_df['gender'].value_counts()\n",
        "\n",
        "# Output results\n",
        "print(\"Summary Statistics:\")\n",
        "print(summary_statistics)\n",
        "\n",
        "print(\"\\nSpecies Counts:\")\n",
        "print(species_counts)\n",
        "\n",
        "print(\"\\nPersonality Counts:\")\n",
        "print(personality_counts)\n",
        "\n",
        "print(\"\\nGender Counts:\")\n",
        "print(gender_counts)\n",
        "\n"
      ],
      "metadata": {
        "id": "odDQBQv-ZIG1",
        "outputId": "f777e17e-e431-40f6-802b-3a6e6e26406a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Statistics:\n",
            "            row_n\n",
            "count  391.000000\n",
            "mean   239.902813\n",
            "std    140.702672\n",
            "min      2.000000\n",
            "25%    117.500000\n",
            "50%    240.000000\n",
            "75%    363.500000\n",
            "max    483.000000\n",
            "\n",
            "Species Counts:\n",
            "species\n",
            "cat          23\n",
            "rabbit       20\n",
            "frog         18\n",
            "squirrel     18\n",
            "duck         17\n",
            "dog          16\n",
            "cub          16\n",
            "pig          15\n",
            "bear         15\n",
            "mouse        15\n",
            "horse        15\n",
            "bird         13\n",
            "penguin      13\n",
            "sheep        13\n",
            "elephant     11\n",
            "wolf         11\n",
            "ostrich      10\n",
            "deer         10\n",
            "eagle         9\n",
            "gorilla       9\n",
            "chicken       9\n",
            "koala         9\n",
            "goat          8\n",
            "hamster       8\n",
            "kangaroo      8\n",
            "monkey        8\n",
            "anteater      7\n",
            "hippo         7\n",
            "tiger         7\n",
            "alligator     7\n",
            "lion          7\n",
            "bull          6\n",
            "rhino         6\n",
            "cow           4\n",
            "octopus       3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Personality Counts:\n",
            "personality\n",
            "lazy      60\n",
            "normal    59\n",
            "cranky    55\n",
            "snooty    55\n",
            "jock      55\n",
            "peppy     49\n",
            "smug      34\n",
            "uchi      24\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Gender Counts:\n",
            "gender\n",
            "male      204\n",
            "female    187\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "pXDBDM9n9ipr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\")\n",
        "\n",
        "# Display the shape of the dataset\n",
        "print(\"Dataset Shape (rows, columns):\", df.shape)\n",
        "\n",
        "# Display the statistical summary of numeric columns\n",
        "print(\"\\nSummary Statistics (Numeric Columns Only):\")\n",
        "print(df.describe())\n",
        "\n",
        "# Explanation of differences\n",
        "print(\"\\nExplanation:\")\n",
        "print(\"1. df.shape shows the total number of rows and columns.\")\n",
        "print(\"2. df.describe() only analyzes numeric columns, so non-numeric columns are not shown (like 'Sex', 'Name').\")\n",
        "print(\"3. The 'count' in df.describe() reflects the number of non-missing values for each numeric column.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt6fe_jT_pLd",
        "outputId": "db61f5bc-2158-4344-c5e4-7e8ed58e37f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape (rows, columns): (891, 15)\n",
            "\n",
            "Summary Statistics (Numeric Columns Only):\n",
            "         survived      pclass         age       sibsp       parch        fare\n",
            "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
            "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
            "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
            "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
            "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
            "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
            "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
            "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
            "\n",
            "Explanation:\n",
            "1. df.shape shows the total number of rows and columns.\n",
            "2. df.describe() only analyzes numeric columns, so non-numeric columns are not shown (like 'Sex', 'Name').\n",
            "3. The 'count' in df.describe() reflects the number of non-missing values for each numeric column.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the difference between df.shape and df.describe essentially lies between the differences in what they are analyzing.  The function df.shape analyzes both numeric variables (think age) and non numeric variables (think gender).  On the other hand, df.describe() solely looks at the numeric variables and shows calculations such as mean, standard deviation, etc.  "
      ],
      "metadata": {
        "id": "lLS3X6p0-FuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "ggLwepfeNqPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essentially, methods versus attributes are different due to the differences in calculations.  Methods needs parentheses because they perform a calculation, such as finding the mean of age for example.  While attributes don't perform \"calculations\", rather they state things that are sort of \"just true\" about the dataset, such as the number of columns and rows."
      ],
      "metadata": {
        "id": "3mO3dGGROIfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6"
      ],
      "metadata": {
        "id": "8MsMOFPQhtVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some quick definitions of all of the summary statistics provided by df.describe()\n",
        "\n",
        "Count: provides the number of valid entries in each column.  Essentially, how many 'non-empty' values each column has.\n",
        "\n",
        "Mean: an average of all of the data points in that specific column.  This is found by summing all of the individual data points, and then dividing it by the total number of valid data points (like the number in the 'count' statistic) in that column.\n",
        "\n",
        "Minimun (min): The smallest value in that column.\n",
        "\n",
        "25%: The first quartile, it is the point where 25% of the data lies below this value.\n",
        "\n",
        "50%: The second quartile, the point where 50% of the data lies below that value, also referred to as the median.\n",
        "\n",
        "75%: The third quartile, the point where 75% of the data lies below this value.\n",
        "\n",
        "Maximum (max): The largest value in that column."
      ],
      "metadata": {
        "id": "M6dFB2tthwPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7"
      ],
      "metadata": {
        "id": "lEVGXS1sjuIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Using df.dropna() would be beneficial in cases when you don't have a large amount of data missing, but relatively smaller amounts across rows.\n",
        "Take the Titanic dataset below."
      ],
      "metadata": {
        "id": "PyxzzmaB10yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Check for missing values in each column\n",
        "missing_data = df.isnull().sum()\n",
        "\n",
        "# Print the total number of missing values and which columns contain missing data\n",
        "print(missing_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz4qk9V72wM9",
        "outputId": "66edd4ae-5e5a-4121-feae-86a965f1bacb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "survived         0\n",
            "pclass           0\n",
            "sex              0\n",
            "age            177\n",
            "sibsp            0\n",
            "parch            0\n",
            "fare             0\n",
            "embarked         2\n",
            "class            0\n",
            "who              0\n",
            "adult_male       0\n",
            "deck           688\n",
            "embark_town      2\n",
            "alive            0\n",
            "alone            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 2 passengers have missing data in the 'embark_town' column, and it would be unreasonable to delete this entire column for that reason, therefore it is a better idea to use df.dropna() for this case."
      ],
      "metadata": {
        "id": "Q5tge5aH23Aw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using the missing values table from questionn 1, we can see how the 'deck' column has 688 missing values.  This is an overwhelming majority of the data which does not have values here, and using df.dropna() to remove every one of these rows would be completely unreasonable as a large amount of the other columns of data would be removed.  In this case, using del df['col'] would be a better choice.\n"
      ],
      "metadata": {
        "id": "105nV-Xl3PQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Using del df['col'] before df.dropna() is a better idea because let's say a majority of the data in a column is missing (say 70%+), if you used df.dropna() first on these rows, that would mean that a huge amount of usable data will be lost.  As opposed to using del df['col'] first, in which case this entire column will be delete, and then you can individually take out other rows using df.dropna() where you can retain as much usable data as possible."
      ],
      "metadata": {
        "id": "npjS8tq_4Qsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. In order to most efficiently remove data from the dataset, I will remove the 'deck' column first, and then remove the rows of missing data from 'age', 'embarked', and 'embark_town'."
      ],
      "metadata": {
        "id": "CYuzw2u24621"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Titanic dataset again to ensure a fresh start\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Check initial shape of the dataset\n",
        "print(\"Initial shape: \", df.shape)\n",
        "\n",
        "# Step 1: Delete the 'deck' column, which has too many missing values\n",
        "del df['deck']\n",
        "\n",
        "# Report shape after deleting 'deck'\n",
        "print(\"After deleting 'deck': \", df.shape)\n",
        "\n",
        "# Step 2: Drop rows where essential columns have missing values (age, embarked and embark_town)\n",
        "df_clean = df.dropna(subset=['age', 'embarked', 'embark_town'])\n",
        "\n",
        "# Report shape after dropping missing values\n",
        "print(\"After dropping rows with missing values: \", df_clean.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ65rdui6b5Z",
        "outputId": "24667ff5-cead-4bac-f6c8-b3146ca1be2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial shape:  (891, 15)\n",
            "After deleting 'deck':  (891, 14)\n",
            "After dropping rows with missing values:  (712, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justification: As you can see, we were able to still keep a majority of the data.  Keeping 712 out of 891 rows and 14 out of 15 columns, if we used a different approach (say removing the rows of missing data for 'deck' first) we would end up with a much smaller set of data."
      ],
      "metadata": {
        "id": "QyaMRX6L6qDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 8"
      ],
      "metadata": {
        "id": "YUDAKdrh84mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Group by 'class' and summarize statistics for 'fare'\n",
        "grouped_summary = df.groupby(\"class\")[\"fare\"].describe()\n",
        "print(grouped_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AYnekOK90gG",
        "outputId": "a84c7a22-6538-43c2-d832-4faa2f7909a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        count       mean        std  min       25%      50%   75%       max\n",
            "class                                                                      \n",
            "First   216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
            "Second  184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
            "Third   491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. As you can see from code above, I chose to compare class to fare.  What we can see is that putting class as 'col1' results in class being on the rows, and the different 'fare' values are analysed against the class using the .describe() function's different numerical stats.  What this is essentially doing is analysing all of the different statistics of each class and presenting them so we can compare, for example, we can see how in the 'mean' category, first class had paid a lot more than second or third, which of course makes sense.  However this provides us with the ability to make more niche, less obvious conclusions."
      ],
      "metadata": {
        "id": "vCQ9ffQR858y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The key difference between groupby() and describe() is that describe() provides the overall summary stats for the entire dataset.  Specifically for all non-missing values.  On the other hand, groupby() specifically breaks down the stats in the 'col2' into the different groups of 'col1'. Using the previous part (1) as an example, the fare is split into the categories 'First', 'Second' and 'Third', whereas if we used just describe(), it would provide stats for  the entire dataset, not broken down into specific categories."
      ],
      "metadata": {
        "id": "lTLdsVuA_j1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. IN ORDER TO NOT LOSE THE CODE I HAVE ALREADY RAN, I RAN THE ERRORS IN A NEW NOTEBOOK AND PASTED THE LINK FOR THE NOTEBOOK ON MY REPO HERE.\n",
        "\n",
        "https://github.com/nehan-p/sta130/blob/main/STA130HW1ErrorQuestion.ipynb\n"
      ],
      "metadata": {
        "id": "LLzEOL4UBpSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Summary"
      ],
      "metadata": {
        "id": "5v8C3N8NxdYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the link for my chatbot conversation and a summary of the chat.\n",
        "\n",
        "NOTE - I was not able to download the direct link for my conversation through ChatGPT since an error kept occurring, so I downloaded the pdf and uploaded it to my github, which the link for is here.\n",
        "\n",
        "https://github.com/nehan-p/sta130/blob/main/Dataset%20Columns%20Summary.pdf\n",
        "\n",
        "\n",
        "Dataset Exploration:\n",
        "\n",
        "You were working with the Titanic dataset from the URL https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv.\n",
        "We explored missing data using df.isnull().sum() to check how much data was missing and where.\n",
        "We discussed the differences between df.shape and df.describe(), explaining why they give different information due to non-numeric columns and missing values.\n",
        "Explanation of Summary Statistics:\n",
        "\n",
        "I provided definitions for the various summary statistics generated by df.describe(), such as 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max'.\n",
        "Handling Missing Data:\n",
        "\n",
        "We explored two approaches to dealing with missing data: df.dropna() and del df['column'].\n",
        "You learned about use cases for when each method might be preferred and how they can be applied to optimize the use of non-missing data.\n",
        "GroupBy Operation:\n",
        "\n",
        "You experimented with using df.groupby(\"class\")[\"alive\"].describe() to get group-level statistics and learned why not all describe statistics are shown (for categorical data only certain statistics like count, unique, top, and freq are relevant).\n",
        "Error Debugging:\n",
        "\n",
        "We walked through some common coding errors like NameError: name 'pd' is not defined, fixing typos, missing parentheses, and handling column name errors.\n",
        "I explained how to simulate and fix these errors, including restarting the kernel and re-importing libraries in Google Colab.\n",
        "GitHub Upload:\n",
        "\n",
        "You asked how to upload your Jupyter notebook to GitHub. I guided you through saving the notebook from Google Colab, uploading it to GitHub via the web interface, and then submitting the link to your Quercus assignment.\n",
        "Final Steps:\n",
        "\n",
        "You requested help with inserting screenshots into your Google Colab notebook and I explained how to do this.\n",
        "I provided instructions for uploading the notebook to GitHub and submitting it for your assignment.\n"
      ],
      "metadata": {
        "id": "A_ncC_xFxgau"
      }
    }
  ]
}